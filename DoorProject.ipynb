{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f6e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9937a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Aizat/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-5 Python-3.9.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be82cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Aizat/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-2-5 Python-3.9.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7018216 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "#Custom Model\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path='konlovephone.pt')\n",
    "#model = torch.hub.load('ultralytics/yolov5', 'custom', path='gesture3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c31a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "confi_threshold = 0.50 #threshold value for confidence score. if the gesture exceeds this value, it is accepted as true\n",
    "gesturePresent = False;\n",
    "startTime = 0;\n",
    "elapseTime = 0;\n",
    "delayDetection = 3; #how long to hold the gesture for\n",
    "scanning_class = -1;\n",
    "\n",
    "display_msg = '';\n",
    "\n",
    "facePresent = False;\n",
    "startTime_faceDet = 0;\n",
    "elapseTime_faceDet = 0;\n",
    "delayDetection_face = 6.0; #how long to hold the face for\n",
    "\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "masterPassword = [1,1,0]; #master password refers to the the class numbers in order\n",
    "print(masterPassword) #printers the master password\n",
    "\n",
    "\n",
    "#class number classification\n",
    "#kon - 0\n",
    "#minilove - 1\n",
    "#telephone - 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2477c9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Face Detected; Timer Reset\n",
      "Face is Detected\n",
      "Gesture Recognised - 1.0\n",
      "Gesture Recognised - 2.0\n",
      "Gesture Recognised - 2.0\n",
      "Wrong Password\n",
      "[1, 2, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow(\"img\", cv2.WINDOW_NORMAL)\n",
    "  \n",
    "# Using resizeWindow()\n",
    "cv2.resizeWindow(\"img\", 900, 700)\n",
    "password = [];\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    \n",
    "    #reads the frames\n",
    "    _, img = cap.read()\n",
    "    \n",
    "    \n",
    "    #convert to grayscaleq\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect the faces\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.1, 4)\n",
    "    \n",
    "    #If a new Face is Present\n",
    "    if len(faces) == 1 and (startTime_faceDet == 0):\n",
    "        facePresent = True;\n",
    "        startTime_faceDet = time.time();\n",
    "    \n",
    "    #if only 1 face is present, checks if the holding time is enough\n",
    "    if len(faces) == 1 and (startTime_faceDet > 0):\n",
    "        elapseTime_faceDet = round((time.time() - startTime_faceDet), 2);\n",
    "        if(elapseTime_faceDet > delayDetection_face):\n",
    "            print(\"Face is Detected\")\n",
    "            break;\n",
    "    \n",
    "    #places the text\n",
    "    pic = cv2.putText(img, str(elapseTime_faceDet), (5,50), cv2.FONT_HERSHEY_PLAIN, 5 ,(0, 0, 255));\n",
    "    \n",
    "    #if no face is detected or more than 1 is detected, reset the timer\n",
    "    if (len(faces) == 0 or len(faces) > 1):\n",
    "        facePresent = False;\n",
    "        startTime_faceDet = 0;\n",
    "        print('No Face Detected; Timer Reset');\n",
    "        pic = cv2.putText(img, \"No Face Detected\", (5,60), cv2.FONT_HERSHEY_PLAIN, 5 ,(0, 0, 255));\n",
    "    \n",
    "    \n",
    "    # Draw the rectangle around each face\n",
    "    for (x, y, w, h) in faces:\n",
    "        pic = cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    # Display\n",
    "    cv2.imshow('img', pic)\n",
    "    \n",
    "    # Stop if escape key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release();\n",
    "        cv2.destroyAllWindows();\n",
    "        \n",
    "        \n",
    "while True:\n",
    "    _, frames = cap.read()  #reads each frame\n",
    "    results = model(frames) #has the model predict the frame and predicts for objects \n",
    "    \n",
    "    #debug\n",
    "    #print('---------------------')\n",
    "    #print(results.pandas().xyxy[0])\n",
    "    #print('Detected Gestures : ' + str(len(results.pandas().xyxy[0])))\n",
    "    \n",
    "    max_detected_confi = 0;\n",
    "    \n",
    "    #for each object detected \n",
    "    for i in range(0, len(results.pandas().xyxy[0])):\n",
    "        confi = results.xyxy[0][i][4].numpy() #retrieves the confidence score\n",
    "        #print(results.pandas().xyxy[0]);\n",
    "        \n",
    "        #takes the highest confidence score gesture. Instead of ensuring only 1 gesture is present. We just take the highest score present in the list\n",
    "        if confi > max_detected_confi:\n",
    "            max_detected_confi = confi\n",
    "            x0,y0,x1,y1,confi,cla = results.xyxy[0][i].numpy() #retrieves the bounding box points, confidence score, class,\n",
    "            \n",
    "            origin = (x0.astype(int), y0.astype(int));\n",
    "            end = (x1.astype(int), y1.astype(int));\n",
    "            \n",
    "            #label = cv2.rectangle(frames, origin,end, (255,0,0), 2 )\n",
    "            \n",
    "            label = cv2.rectangle(frames, origin, end, (255,255,0), 2 )\n",
    "            label = cv2.putText(frames, str(cla), (x0.astype(int), y0.astype(int) + 10), cv2.FONT_HERSHEY_PLAIN, 6 ,(0, 255, 255));\n",
    "            \n",
    "            \n",
    "        \n",
    "    if confi > confi_threshold:\n",
    "        \n",
    "        #If a new gesture is Present\n",
    "        if (startTime == 0):\n",
    "            scanning_class = cla\n",
    "            gesturePresent = True;\n",
    "            startTime = time.time();\n",
    "        \n",
    "        #if same class as before, start time\n",
    "        if (scanning_class == cla and startTime > 0):\n",
    "            elapseTime = round((time.time() - startTime), 2)\n",
    "            label = cv2.putText(frames, str(elapseTime), (5, 30), cv2.FONT_HERSHEY_PLAIN, 6 ,(0, 0, 255));\n",
    "            #if passes 3 three seconds, that gesture is added to the bank\n",
    "            #print(elapseTime)\n",
    "            if(elapseTime > delayDetection):    \n",
    "                display_msg = \"Gesture Recognised - \" + str(cla);\n",
    "                password.append(int(cla));\n",
    "                print(display_msg)\n",
    "                startTime = 0;\n",
    "                    \n",
    "    \n",
    "    if (scanning_class != cla or confi < confi_threshold):\n",
    "        gesturePresent = False;\n",
    "        startTime = 0;\n",
    "        #print('Bad Input. No Gesture Recognised or Not Clear');\n",
    "            \n",
    "    #if 3 inputs are detected        \n",
    "    if (len(password) > 2):\n",
    "        if password == masterPassword:\n",
    "            print(\"You have Entered the Correct Password\");\n",
    "        else:\n",
    "            print(\"Wrong Password\");\n",
    "        print(password);\n",
    "        break\n",
    "    \n",
    "    #converts to a string \n",
    "    pass_text = ''.join(str(x) for x in password); \n",
    "    label = cv2.putText(frames, pass_text, (5, 500), cv2.FONT_HERSHEY_PLAIN, 6 ,(0, 0, 255));\n",
    "    cv2.imshow('img', label)\n",
    "    \n",
    "    \n",
    "    # Stop if escape key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cap.release();\n",
    "        cv2.destroyAllWindows();\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "cap.release();\n",
    "cv2.destroyAllWindows();\n",
    "\n",
    "#gets the time when the person entered. \n",
    "time_enter = datetime.now().strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
    "\n",
    "saveFile = cv2.putText(img, time_enter, (5, 60), cv2.FONT_HERSHEY_PLAIN, 6 ,(0, 0, 255));\n",
    "filename = 'savedImage.jpg'\n",
    "cv2.imwrite(filename, saveFile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "7c671e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release();\n",
    "cv2.destroyAllWindows();\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
